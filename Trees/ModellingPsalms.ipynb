{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6309d20d-bd9d-4bc6-b992-6b49ef706e5f",
   "metadata": {},
   "source": [
    "### Modelling the grammar of the Psalms\n",
    "\n",
    "This notebook will explore the use of grammatical features to classify sentences from the book of Genesis and the Psalms. The basic idea is to build a dataset of observations with each row representing a sentence and each column representing the count of a grammatical feature within the sentence. This dataset will then be used with a logistic regression model to investigate which grammatical features are most significant in determining whether a sentence is more likely to be from Genesis or Psalms. (I chose logistic regression because it is simple and interpretable, in the future it will be a good idea to try other models). \n",
    "\n",
    "The goal of the notebook is to illustrate a technique for incorporating statistical modelling into the analysis of biblical literature. Note that I have not put a great deal of effort into refining the model at this point and it could surely be improved by thinking a little more carefully about which features to capture and record. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f41e423f-d91f-4a4b-a28b-56750ea5c069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b title=\"local commit\">TF-app:</b> <span title=\"#a9bed226b97263e449fd0f189792dbff86f9333f offline under ~/text-fabric-data\">~/text-fabric-data/annotation/app-bhsa/code</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local release\">data:</b> <span title=\"rv1.6=#bac4a9f5a2bbdede96ba6caea45e762fe88f88c5 offline under ~/text-fabric-data\">~/text-fabric-data/etcbc/bhsa/tf/c</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local release\">data:</b> <span title=\"r1.2=#1ac68e976ee4a7f23eb6bb4c6f401a033d0ec169 offline under ~/text-fabric-data\">~/text-fabric-data/etcbc/phono/tf/c</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local release\">data:</b> <span title=\"r1.2=#395dfe2cb69c261862fab9f0289e594a52121d5c offline under ~/text-fabric-data\">~/text-fabric-data/etcbc/parallels/tf/c</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Text-Fabric:</b> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/tf/cheatsheet.html\" title=\"text-fabric-api\">Text-Fabric API 8.4.14</a>, <a target=\"_blank\" href=\"https://github.com/annotation/app-bhsa\" title=\"bhsa TF-app\">app-bhsa v3</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/tf/about/searchusage.html\" title=\"Search Templates Introduction and Reference\">Search Reference</a><br><b>Data:</b> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/0_home\" title=\"provenance of BHSA = Biblia Hebraica Stuttgartensia Amstelodamensis\">BHSA</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/tf/writing/hebrew.html\" title=\"How TF features represent text\">Character table</a>, <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/0_home\" title=\"BHSA feature documentation\">Feature docs</a><br><b>Features:</b><br><details><summary><b>Parallel Passages</b></summary><b><i><a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/parallels/blob/master/programs/parallels.ipynb\" title=\"~/text-fabric-data/etcbc/parallels/tf/c/crossref.tf\">crossref</a></i></b><br></details><details><summary><b>BHSA = Biblia Hebraica Stuttgartensia Amstelodamensis</b></summary><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/book\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/book.tf\">book</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/book@ll\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/book@am.tf\">book@ll</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/chapter\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/chapter.tf\">chapter</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/code\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/code.tf\">code</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/det\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/det.tf\">det</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/domain\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/domain.tf\">domain</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/freq_lex\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/freq_lex.tf\">freq_lex</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/function\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/function.tf\">function</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_cons\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/g_cons.tf\">g_cons</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_cons_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/g_cons_utf8.tf\">g_cons_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_lex\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/g_lex.tf\">g_lex</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_lex_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/g_lex_utf8.tf\">g_lex_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_word\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/g_word.tf\">g_word</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_word_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/g_word_utf8.tf\">g_word_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/gloss\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/gloss.tf\">gloss</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/gn\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/gn.tf\">gn</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/label\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/label.tf\">label</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/language\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/language.tf\">language</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/lex\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/lex.tf\">lex</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/lex_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/lex_utf8.tf\">lex_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/ls\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/ls.tf\">ls</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/nametype\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/nametype.tf\">nametype</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/nme\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/nme.tf\">nme</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/nu\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/nu.tf\">nu</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/number\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/number.tf\">number</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/otype\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/otype.tf\">otype</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/pargr\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/pargr.tf\">pargr</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/pdp\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/pdp.tf\">pdp</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/pfm\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/pfm.tf\">pfm</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/prs\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/prs.tf\">prs</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/prs_gn\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/prs_gn.tf\">prs_gn</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/prs_nu\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/prs_nu.tf\">prs_nu</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/prs_ps\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/prs_ps.tf\">prs_ps</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/ps\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/ps.tf\">ps</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/qere\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/qere.tf\">qere</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/qere_trailer\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/qere_trailer.tf\">qere_trailer</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/qere_trailer_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/qere_trailer_utf8.tf\">qere_trailer_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/qere_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/qere_utf8.tf\">qere_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/rank_lex\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/rank_lex.tf\">rank_lex</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/rela\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/rela.tf\">rela</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/sp\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/sp.tf\">sp</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/st\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/st.tf\">st</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/tab\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/tab.tf\">tab</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/trailer\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/trailer.tf\">trailer</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/trailer_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/trailer_utf8.tf\">trailer_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/txt\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/txt.tf\">txt</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/typ\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/typ.tf\">typ</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/uvf\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/uvf.tf\">uvf</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/vbe\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/vbe.tf\">vbe</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/vbs\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/vbs.tf\">vbs</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/verse\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/verse.tf\">verse</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/voc_lex\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/voc_lex.tf\">voc_lex</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/voc_lex_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/voc_lex_utf8.tf\">voc_lex_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/vs\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/vs.tf\">vs</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/vt\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/vt.tf\">vt</a><br><b><i><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/mother\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/mother.tf\">mother</a></i></b><br><b><i><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/oslots\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/oslots.tf\">oslots</a></i></b><br></details><details><summary><b>Phonetic Transcriptions</b></summary><a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/phono/blob/master/programs/phono.ipynb\" title=\"~/text-fabric-data/etcbc/phono/tf/c/phono.tf\">phono</a><br><a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/phono/blob/master/programs/phono.ipynb\" title=\"~/text-fabric-data/etcbc/phono/tf/c/phono_trailer.tf\">phono_trailer</a><br></details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>tr.tf.ltr, td.tf.ltr, th.tf.ltr { text-align: left ! important;}\n",
       "tr.tf.rtl, td.tf.rtl, th.tf.rtl { text-align: right ! important;}\n",
       "@font-face {\n",
       "  font-family: \"Gentium Plus\";\n",
       "  src: local('Gentium Plus'), local('GentiumPlus'),\n",
       "    url('/server/static/fonts/GentiumPlus-R.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/GentiumPlus-R.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Ezra SIL\";\n",
       "  src: local('Ezra SIL'), local('EzraSIL'),\n",
       "    url('/server/static/fonts/SILEOT.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SILEOT.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"SBL Hebrew\";\n",
       "  src: local('SBL Hebrew'), local('SBLHebrew'),\n",
       "    url('/server/static/fonts/SBL_Hbrw.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SBL_Hbrw.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Estrangelo Edessa\";\n",
       "  src: local('Estrangelo Edessa'), local('EstrangeloEdessa');\n",
       "    url('/server/static/fonts/SyrCOMEdessa.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SyrCOMEdessa.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: AmiriQuran;\n",
       "  font-style: normal;\n",
       "  font-weight: 400;\n",
       "  src: local('Amiri Quran'), local('AmiriQuran'),\n",
       "    url('/server/static/fonts/AmiriQuran.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/AmiriQuran.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: AmiriQuranColored;\n",
       "  font-style: normal;\n",
       "  font-weight: 400;\n",
       "  src: local('Amiri Quran Colored'), local('AmiriQuranColored'),\n",
       "    url('/server/static/fonts/AmiriQuranColored.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/AmiriQuranColored.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Santakku\";\n",
       "  src: local('Santakku'),\n",
       "    url('/server/static/fonts/Santakku.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/Santakku.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"SantakkuM\";\n",
       "  src: local('SantakkuM'),\n",
       "    url('/server/static/fonts/SantakkuM.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SantakkuM.woff?raw=true') format('woff');\n",
       "}\n",
       "/* bypassing some classical notebook settings */\n",
       "div#notebook {\n",
       "  line-height: unset;\n",
       "}\n",
       "/* neutral text */\n",
       ".txtn,.txtn a:visited,.txtn a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* transcription text */\n",
       ".txtt,.txtt a:visited,.txtt a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* source text */\n",
       ".txto,.txto a:visited,.txto a:link {\n",
       "    font-family: serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* phonetic text */\n",
       ".txtp,.txtp a:visited,.txtp a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* original script text */\n",
       ".txtu,.txtu a:visited,.txtu a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* hebrew */\n",
       ".txtu.hbo,.lex.hbo {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* syriac */\n",
       ".txtu.syc,.lex.syc {\n",
       "    font-family: \"Estrangelo Edessa\", sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* neo aramaic */\n",
       ".txtu.cld,.lex.cld {\n",
       "    font-family: \"CharisSIL-R\", sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* standard arabic */\n",
       ".txtu.ara,.lex.ara {\n",
       "    font-family: \"AmiriQuran\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* cuneiform */\n",
       ".txtu.akk,.lex.akk {\n",
       "    font-family: Santakku, sans-serif;\n",
       "    font-size: large;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* greek */\n",
       ".txtu.grc,.lex.grc a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "a:hover {\n",
       "    text-decoration: underline | important;\n",
       "    color: #0000ff | important;\n",
       "}\n",
       ".ltr {\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".rtl {\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".ubd {\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".col {\n",
       "   display: inline-block;\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: var(--features);\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    padding: 2px;\n",
       "    margin: 2px;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    border: var(--meta-width) solid var(--meta-color);\n",
       "    border-radius: var(--meta-width);\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -2px 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 2px 0px;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: small;\n",
       "  font-weight: normal;\n",
       "}\n",
       ".tfsechead {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: var(--tfsechead);\n",
       "    unicode-bidi: embed;\n",
       "    text-align: start;\n",
       "}\n",
       ".structure {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: var(--structure);\n",
       "    unicode-bidi: embed;\n",
       "    text-align: start;\n",
       "}\n",
       ".comments {\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".nd, a:link.nd {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    color: var(--node);\n",
       "    vertical-align: super;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".lex {\n",
       "  color: var(--lex-color);;\n",
       "}\n",
       ".children,.children.ltr {\n",
       "    display: flex;\n",
       "    border: 0;\n",
       "    background-color: #ffffff;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "}\n",
       ".children.stretch {\n",
       "    align-items: stretch;\n",
       "}\n",
       ".children.hor {\n",
       "    flex-flow: row nowrap;\n",
       "}\n",
       ".children.hor.wrap {\n",
       "    flex-flow: row wrap;\n",
       "}\n",
       ".children.ver {\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".children.ver.wrap {\n",
       "    flex-flow: column wrap;\n",
       "}\n",
       ".contnr {\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding:  10px 2px 2px 2px;\n",
       "    margin: 16px 2px 2px 2px;\n",
       "    border-style: solid;\n",
       "    font-size: small;\n",
       "}\n",
       ".contnr.trm {\n",
       "    background-attachment: local;\n",
       "}\n",
       ".contnr.cnul {\n",
       "    padding:  0;\n",
       "    margin: 0;\n",
       "    border-style: solid;\n",
       "    font-size: xx-small;\n",
       "}\n",
       ".contnr.cnul,.lbl.cnul {\n",
       "    border-color: var(--border-color-nul);\n",
       "    border-width: var(--border-width-nul);\n",
       "    border-radius: var(--border-width-nul);\n",
       "}\n",
       ".contnr.c0,.lbl.c0 {\n",
       "    border-color: var(--border-color0);\n",
       "    border-width: var(--border-width0);\n",
       "    border-radius: var(--border-width0);\n",
       "}\n",
       ".contnr.c1,.lbl.c1 {\n",
       "    border-color: var(--border-color1);\n",
       "    border-width: var(--border-width1);\n",
       "    border-radius: var(--border-width1);\n",
       "}\n",
       ".contnr.c2,.lbl.c2 {\n",
       "    border-color: var(--border-color2);\n",
       "    border-width: var(--border-width2);\n",
       "    border-radius: var(--border-width2);\n",
       "}\n",
       ".contnr.c3,.lbl.c3 {\n",
       "    border-color: var(--border-color3);\n",
       "    border-width: var(--border-width3);\n",
       "    border-radius: var(--border-width3);\n",
       "}\n",
       ".contnr.c4,.lbl.c4 {\n",
       "    border-color: var(--border-color4);\n",
       "    border-width: var(--border-width4);\n",
       "    border-radius: var(--border-width4);\n",
       "}\n",
       "span.plain {\n",
       "    display: inline-block;\n",
       "    white-space: pre-wrap;\n",
       "}\n",
       ".plain {\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".plain.l,.contnr.l,.contnr.l>.lbl {\n",
       "    border-left-style: dotted\n",
       "}\n",
       ".plain.r,.contnr.r,.contnr.r>.lbl {\n",
       "    border-right-style: dotted\n",
       "}\n",
       ".plain.lno,.contnr.lno,.contnr.lno>.lbl {\n",
       "    border-left-style: none\n",
       "}\n",
       ".plain.rno,.contnr.rno,.contnr.rno>.lbl {\n",
       "    border-right-style: none\n",
       "}\n",
       ".plain.l {\n",
       "    padding-left: 4px;\n",
       "    margin-left: 2px;\n",
       "    border-width: var(--border-width-plain);\n",
       "}\n",
       ".plain.r {\n",
       "    padding-right: 4px;\n",
       "    margin-right: 2px;\n",
       "    border-width: var(--border-width-plain);\n",
       "}\n",
       ".lbl {\n",
       "    font-family: monospace;\n",
       "    margin-top: -24px;\n",
       "    margin-left: 20px;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 6px;\n",
       "    border-style: solid;\n",
       "    display: block;\n",
       "    color: var(--label)\n",
       "}\n",
       ".lbl.trm {\n",
       "    background-attachment: local;\n",
       "    margin-top: 2px;\n",
       "    margin-left: 2px;\n",
       "    padding: 2px 2px;\n",
       "    border-style: none;\n",
       "}\n",
       ".lbl.cnul {\n",
       "    font-size: xx-small;\n",
       "}\n",
       ".lbl.c0 {\n",
       "    font-size: small;\n",
       "}\n",
       ".lbl.c1 {\n",
       "    font-size: small;\n",
       "}\n",
       ".lbl.c2 {\n",
       "    font-size: medium;\n",
       "}\n",
       ".lbl.c3 {\n",
       "    font-size: medium;\n",
       "}\n",
       ".lbl.c4 {\n",
       "    font-size: large;\n",
       "}\n",
       ".occs, a:link.occs {\n",
       "    font-size: small;\n",
       "}\n",
       "\n",
       "/* PROVENANCE */\n",
       "\n",
       "div.prov {\n",
       "\tmargin: 40px;\n",
       "\tpadding: 20px;\n",
       "\tborder: 2px solid var(--fog-rim);\n",
       "}\n",
       "div.pline {\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "}\n",
       "div.p2line {\n",
       "\tmargin-left: 2em;\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "}\n",
       "div.psline {\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "\tbackground-color: var(--gold-mist-back);\n",
       "}\n",
       "div.pname {\n",
       "\tflex: 0 0 5rem;\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.pval {\n",
       "    flex: 1 1 auto;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--node:               hsla(120, 100%,  20%, 1.0  );\n",
       "\t--label:              hsla(  0, 100%,  20%, 1.0  );\n",
       "\t--tfsechead:          hsla(  0, 100%,  25%, 1.0  );\n",
       "\t--structure:          hsla(120, 100%,  25%, 1.0  );\n",
       "\t--features:           hsla(  0,   0%,  30%, 1.0  );\n",
       "  --text-color:         hsla( 60,  80%,  10%, 1.0  );\n",
       "  --lex-color:          hsla(220,  90%,  60%, 1.0  );\n",
       "  --meta-color:         hsla(  0,   0%,  90%, 0.7  );\n",
       "  --meta-width:         3px;\n",
       "  --border-color-nul:   hsla(  0,   0%,  90%, 0.5  );\n",
       "  --border-color0:      hsla(  0,   0%,  90%, 0.9  );\n",
       "  --border-color1:      hsla(  0,   0%,  80%, 0.9  );\n",
       "  --border-color2:      hsla(  0,   0%,  70%, 0.9  );\n",
       "  --border-color3:      hsla(  0,   0%,  80%, 0.8  );\n",
       "  --border-color4:      hsla(  0,   0%,  60%, 0.9  );\n",
       "  --border-width-nul:   2px;\n",
       "  --border-width0:      2px;\n",
       "  --border-width1:      3px;\n",
       "  --border-width2:      4px;\n",
       "  --border-width3:      6px;\n",
       "  --border-width4:      5px;\n",
       "  --border-width-plain: 2px;\n",
       "}\n",
       ".hl {\n",
       "  background-color: var(--hl-strong);\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 2px;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "div.contnr.hl,div.lbl.hl {\n",
       "  background-color: var(--hl-strong);\n",
       "}\n",
       "div.contnr.hl {\n",
       "  border-color: var(--hl-rim) ! important;\n",
       "\tborder-width: 4px ! important;\n",
       "}\n",
       "\n",
       "span.hlbx {\n",
       "\tborder-color: var(--hl-rim);\n",
       "\tborder-width: 4px ! important;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 6px;\n",
       "  padding: 4px;\n",
       "  margin: 4px;\n",
       "}\n",
       "\n",
       "span.plain {\n",
       "  display: inline-block;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55,  80%,  50%, 1.0  );\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Text-Fabric API:</b> names <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/tf/cheatsheet.html\" title=\"doc\">N F E L T S C TF</a> directly usable</div><hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "from nltk import *\n",
    "from tf.app import use\n",
    "import random\n",
    "A = use('bhsa', hoist=globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8786e38e-2c77-4599-a5b9-570898aff9a4",
   "metadata": {},
   "source": [
    "#### Tree Functions\n",
    "\n",
    "The following functions are used to convert the BHSA data into NLTK tree structure. The linguistic structure can then be more easily analyzed from the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d19f6638-762e-4e26-8463-b8e92d9a2bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------\n",
    "        \n",
    "def get_pos(node, tree):\n",
    "    ''' given the number of a node and a tree, returns the pos of that node in the tree '''\n",
    "    for pos in tree.treepositions():\n",
    "        try:\n",
    "            tree[pos].label()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        else:\n",
    "            #pos_node = int(tree[pos].label()[tree[pos].label().index(':')+1:])\n",
    "            pos_node = int(get_node(pos, tree))\n",
    "            if node == pos_node:\n",
    "                node_pos = pos\n",
    "                \n",
    "    return node_pos\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "def get_node(pos, tree):\n",
    "    '''given a position in a tree, returns the number of the node at that position'''\n",
    "    try:\n",
    "        node = tree[pos].label()[tree[pos].label().index(':')+1:]\n",
    "    except:\n",
    "        node = None\n",
    "        \n",
    "    return node\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "def get_label(pos,tree):\n",
    "    '''given a position in a tree, returns the label of the tree at that position'''\n",
    "    try:\n",
    "        label = tree[pos].label()[:tree[pos].label().index(':')]\n",
    "    except:\n",
    "        label = tree[pos].label()\n",
    "        \n",
    "    return label\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "def tree_string(node):\n",
    "    \n",
    "    ''' Takes BHSA node as root and adds all lower distributional objects to a tree '''\n",
    "    \n",
    "    slots = []\n",
    "    slotlist = []\n",
    "    for s in E.oslots.s(node):\n",
    "        slotlist.append(s)\n",
    "    slots.append((node, slotlist))\n",
    "    \n",
    "    for n in L.d(node):\n",
    "        if F.otype.v(n) == 'word':\n",
    "            slots.append((n, [E.oslots.s(n)[0]]))\n",
    "        else:\n",
    "            slotlist = []\n",
    "            for s in E.oslots.s(n):\n",
    "                slotlist.append(s)\n",
    "            slots.append((n, slotlist))\n",
    "    parse_string = []\n",
    "    root_node = '(S:' + str(node)\n",
    "    parse_string.append(root_node)\n",
    "\n",
    "    for slot in slots[0][1]:\n",
    "        parse_string.append(slot)\n",
    "    \n",
    "    for (label, slot) in slots:\n",
    "    \n",
    "        l = ''\n",
    "        add = False\n",
    "        if F.otype.v(label) == 'sentence_atom':\n",
    "            l = 'S_A'\n",
    "            add = True\n",
    "        elif F.otype.v(label) == 'clause_atom':\n",
    "            l = 'C_A'\n",
    "            add = True\n",
    "        elif F.otype.v(label) == 'phrase_atom':\n",
    "            l = 'P_A'\n",
    "            add = True\n",
    "        elif F.otype.v(label) == 'subphrase':\n",
    "            func = F.function.v(label)\n",
    "            if func == None:\n",
    "                l = 'U'\n",
    "            else:\n",
    "                l = func\n",
    "            add = True\n",
    "\n",
    "        elif F.otype.v(label) == 'word':\n",
    "            l = F.sp.v(label)\n",
    "            add = True\n",
    "        \n",
    "        l = l + \":\" + str(label)\n",
    "    \n",
    "        if add:\n",
    "            open_index = parse_string.index(slot[0])\n",
    "            parse_string.insert(open_index,'('+l)\n",
    "            close_index = parse_string.index(slot[-1])\n",
    "            parse_string.insert(close_index + 1,')')\n",
    "\n",
    "    parse_string.append(')')\n",
    "    new_string = []\n",
    "    for n in parse_string:\n",
    "        if type(n) == int:\n",
    "            #new_string.append(F.g_cons.v(n))\n",
    "            new_string.append(str(n))\n",
    "        else:\n",
    "            new_string.append(n)\n",
    "        \n",
    "    return(' '.join(new_string))\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "def move_func(t):\n",
    "        \n",
    "    ''' Takes distributional tree and rearranges under functional nodes '''\n",
    "    levels = [('phrase', 'P'), ('clause','C')]\n",
    "    for level in levels:\n",
    "        atoms = []\n",
    "        for pos in t.treepositions():\n",
    "            try:\n",
    "                t[pos].label()\n",
    "            except AttributeError:\n",
    "                pass\n",
    "            else:\n",
    "                label = t[pos].label()[:t[pos].label().index(':')]\n",
    "                if label == level[1] +'_A':\n",
    "                    atoms.append((pos, label, t[pos].leaves()))\n",
    "\n",
    "        units = []\n",
    "        labels = []\n",
    "        for n in L.d(node):\n",
    "            if F.otype.v(n) == level[0]:\n",
    "                label = level[1] + ':' + str(n)\n",
    "                labels.append(label)\n",
    "                units.append((label, E.oslots.s(n)))\n",
    "        units_table = {k:[] for k in labels}\n",
    "\n",
    "        # for each unit find all atoms contained in that unit and append tree pos to dict\n",
    "        for unit in units:\n",
    "            for atom in atoms:\n",
    "                result =  all(int(elem) in unit[1] for elem in atom[2])\n",
    "                if result:\n",
    "                    units_table[unit[0]].append(atom[0])\n",
    "\n",
    "        # iterate through labels and build tree from atoms \n",
    "        new_trees = []\n",
    "        deletes = []\n",
    "        for label in labels:\n",
    "            unit_atoms = units_table[label]\n",
    "            trees = []\n",
    "            i = unit_atoms[0][:-1]\n",
    "            for atom in unit_atoms:\n",
    "                tree = t[atom]\n",
    "                trees.append(tree)\n",
    "            new_tree = Tree(label, trees)\n",
    "            new_trees.append((i, new_tree))\n",
    "            for atom in unit_atoms:\n",
    "                deletes.append(atom)\n",
    "                \n",
    "        # delete subtrees that are going to move\n",
    "        for pos in reversed(t.treepositions()):\n",
    "            if pos in deletes:\n",
    "                del t[pos]\n",
    "\n",
    "        # add subtrees in new spot\n",
    "        for tree in reversed(new_trees):\n",
    "            t[tree[0]].insert(0, tree[1])\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "def move_daughter(t, relations):\n",
    "    \n",
    "    ''' Given a functional tree, rearranges dependent phrases into a hierarchical structure. '''\n",
    "\n",
    "    phrases = []\n",
    "    \n",
    "    # traverse tree to find all nodes that may have dependent relations\n",
    "    for pos in reversed(t.treepositions()):\n",
    "        try:\n",
    "            t[pos].label()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        else:\n",
    "            label = get_label(pos, t)\n",
    "            if label == 'U' or label == 'P_A' or label == 'C':\n",
    "                node = int(get_node(pos, t))\n",
    "                rela = F.rela.v(node)\n",
    "                if rela in relations:\n",
    "                    mother = E.mother.f(node)[0]\n",
    "                    phrases.append((node, mother, rela))\n",
    "\n",
    "    for phrase in phrases:\n",
    "        m_node = phrase[1]\n",
    "        m_pos = get_pos(m_node, t)\n",
    "        d_node = phrase[0]\n",
    "        d_pos = get_pos(d_node, t)\n",
    "        copy_tree = t[d_pos]\n",
    "        \n",
    "        mother_pos = t[m_pos].leaves()\n",
    "        daughter_pos = copy_tree.leaves()\n",
    "\n",
    "        if F.otype.v(m_node) == 'word' or phrase[2] == 'Link':\n",
    "            # in these cases insert daughter into node *above* mother\n",
    "            # insert point will be based on position of mother node in this node\n",
    "            i_tree = m_pos[:-1]\n",
    "            if mother_pos[0] < daughter_pos[0]:\n",
    "                i_point = m_pos[-1:][0] + 1\n",
    "            else:\n",
    "                i_point = m_pos[-1:][0] - 1\n",
    "        else:\n",
    "            # otherwise insert point is position of daughter relative to mother\n",
    "            i_tree = m_pos\n",
    "            if mother_pos[0] < daughter_pos[0]:\n",
    "                try:\n",
    "                    i_point = mother_pos.index(str(int(daughter_pos[0])-1)) + 1\n",
    "                except:\n",
    "                    i_point = len(mother_pos)\n",
    "            else:\n",
    "                i_point = 0\n",
    "        \n",
    "        ## move tree by inserting at new position and then deleting at old position\n",
    "        t[i_tree].insert(i_point, copy_tree)\n",
    "        del t[d_pos]\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "def move_para(t):\n",
    "    \n",
    "    ''' Given a tree, rearranges parrallel phrases under a new common node. '''\n",
    "    relations = ['Para', 'Coor']\n",
    "    phrases = []\n",
    "    \n",
    "    # find phrases with relation 'Para' or 'Coor'\n",
    "    for pos in t.treepositions():\n",
    "        try:\n",
    "            t[pos].label()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        else:\n",
    "            label = get_label(pos, t)\n",
    "            if label == 'P' or label == 'P_A' or label == 'C':\n",
    "                node = int(get_node(pos, t))\n",
    "                rela = F.rela.v(node)\n",
    "                if rela in relations:\n",
    "                    mother = E.mother.f(node)[0]\n",
    "                    phrases.append((node, mother, rela))\n",
    "\n",
    "    \n",
    "    mothers = []\n",
    "    daughters = []\n",
    "\n",
    "    for phrase in phrases:\n",
    "        mother = phrase[1]\n",
    "        daughter = phrase[0]\n",
    "        mothers.append(mother)\n",
    "        daughters.append((mother, daughter))\n",
    "    \n",
    "    # build a dict since there may be more than one daughter parallel to the same mother\n",
    "    table = {k:[] for k in mothers}\n",
    "    for d in daughters:\n",
    "        table[d[0]].append(d[1])\n",
    "        \n",
    "    ## get pos for mother and all daughters then build new tree under common node\n",
    "    for mother in reversed(table):\n",
    "        deletes = []\n",
    "        m_pos = get_pos(mother, t)\n",
    "        para_trees = []\n",
    "        para_trees.append(t[m_pos])\n",
    "        for daughter in table[mother]:\n",
    "            d_pos = get_pos(daughter, t)\n",
    "            para_trees.append(t[d_pos])\n",
    "            deletes.append(d_pos)\n",
    "            #del t[d_pos] # delete daughter at current position\n",
    "        old_label = get_label(m_pos, t)\n",
    "        new_label = old_label + ':000'\n",
    "        new_tree = Tree(new_label, para_trees)\n",
    "        \n",
    "        # delete mother at old position\n",
    "        del t[m_pos]\n",
    "\n",
    "        # insert new para phrase in mother position\n",
    "        i_tree = m_pos[:-1]\n",
    "        i_point = m_pos[-1:][0]\n",
    "        t[i_tree].insert(i_point, new_tree)\n",
    "        \n",
    "        # delete daughters\n",
    "        for pos in reversed(t.treepositions()):\n",
    "            if pos in deletes:\n",
    "                del t[pos]\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "def trim_nodes(t):\n",
    "    ''' This function finds empty nodes left after rearrangement and trims them off. '''\n",
    "    deletes = []\n",
    "    for pos in t.treepositions():\n",
    "        if len(t[pos]) == 0:\n",
    "            deletes.append(pos)\n",
    "    \n",
    "    for delete in reversed(deletes):\n",
    "        del t[delete]\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "def collapse_nodes(t):\n",
    "    ''' This function looks for redundant nodes and collapses them. Redundant nodes include \n",
    "    remaining sentence atoms and clause atoms, or other cases where two nodes of the same class \n",
    "    containing the same items are in a mother-daughter relationship   '''\n",
    "    adds = []\n",
    "    for pos in reversed(t.treepositions()[1:]):\n",
    "        try:\n",
    "            t[pos].label()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        else:\n",
    "            match = all(elem in t[pos].leaves() for elem in t[pos[:-1]].leaves())\n",
    "            if ((match and ((t[pos].label()[0] == t[pos[:-1]].label()[0]) or (t[pos].label()[0] == 'U' and t[pos[:-1]].label()[0] == 'P'))) \n",
    "                or (t[pos].label().startswith('C_A'))\n",
    "                or (t[pos].label().startswith('S_A'))):\n",
    "                children = t[pos][0:]\n",
    "                i_point = pos[-1:][0]\n",
    "                del t[pos]\n",
    "                for child in reversed(children):\n",
    "                    t[pos[:-1]].insert(i_point, child)\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "def relabel_tree(t):\n",
    "    ''' This function changes tree labels to reflect phrase/clause type and function as necessary'''\n",
    "    \n",
    "    # these dicts are for converting labels to my preferred (often simpler) form, but this part can use some work \n",
    "    label_dict = {'adjv': 'adj',\n",
    "                  'adjective': 'adj',\n",
    "                  'advb': 'adv',\n",
    "                  'adverb': 'adv',\n",
    "                  'art': 'def',\n",
    "                  'article': 'def',\n",
    "                  'conj': 'conj',\n",
    "                  'conjunction': 'conj',\n",
    "                  'inrg': 'ir',\n",
    "                  'interrogative': 'ir',\n",
    "                  'intj': 'ij',\n",
    "                  'interjection': 'ij',\n",
    "                  'nega': 'neg',\n",
    "                  'negative': 'neg',\n",
    "                  'nmpr': 'pn',\n",
    "                  'pronoun': 'pro',\n",
    "                  'prde': 'pro-dem',\n",
    "                  'prep': 'p',\n",
    "                  'preposition': 'p',\n",
    "                  'prin': 'pro-int',\n",
    "                  'prps': 'pro-ps',\n",
    "                  'subs': 'n',\n",
    "                  'noun': 'n',\n",
    "                  'verb': 'v',\n",
    "                 }\n",
    "    np = ['NP', 'PrNP', 'PPrP', 'DPrP', 'IPrP'] \n",
    "    \n",
    "    \n",
    "    sub_dict = {'adv':'AdvP',\n",
    "                'n':'NP',\n",
    "                'pn':'NP',\n",
    "                'def':'NP',  # need to double check this\n",
    "                'adj':'AdjP',\n",
    "                'p':'PP',\n",
    "                'v':'VP' # this is going to hit on some infinitives/participles, not sure if really VP\n",
    "               }\n",
    "    \n",
    "    # traverse the tree and update each label\n",
    "    for pos in reversed(t.treepositions()):\n",
    "        try:\n",
    "            t[pos].label()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        else:\n",
    "            label = get_label(pos, t)\n",
    "            try:\n",
    "                t[pos].set_label(label_dict[label])\n",
    "            except:  \n",
    "                node = int(get_node(pos,t))\n",
    "                node_type = F.otype.v(node)\n",
    "                func = F.function.v(node)\n",
    "                rela = F.rela.v(node)\n",
    "                typ = F.typ.v(node)\n",
    "                if typ in np:\n",
    "                    typ = 'NP'\n",
    "                \n",
    "                # 1. In case of Coord or Para I added new common node 0, pull lable from first child\n",
    "                if node == 0:\n",
    "                    new_label = t[pos][0].label()\n",
    "                elif node_type == 'sentence' or node_type == 'sentence_atom':\n",
    "                    new_label = 'SENT'\n",
    "                elif node_type == 'clause' or node_type == 'clause_atom':\n",
    "                    if rela == 'NA':\n",
    "                        if typ == None:\n",
    "                            new_label = 'CLAUSE'\n",
    "                        else:\n",
    "                            new_label = 'CLAUSE_' + typ\n",
    "                    else:\n",
    "                        new_label = 'CLAUSE_' + rela\n",
    "                else:\n",
    "                    if typ == 'NegP':\n",
    "                        typ = 'NEG'\n",
    "                        func = ''\n",
    "                    elif typ == 'InjP':\n",
    "                        typ = 'INJ'\n",
    "                        func = ''\n",
    "                    elif typ == 'CP':\n",
    "                        if func == 'Rela':\n",
    "                            typ = 'REL'\n",
    "                            func = ''\n",
    "                        else:\n",
    "                            typ = 'CONJ'\n",
    "                            func = ''\n",
    "                    elif func == None:\n",
    "                        if rela == 'NA' or rela == None:\n",
    "                            func = ''\n",
    "                        else:\n",
    "                            func = '_' + rela\n",
    "                    else:\n",
    "                        func = '_' + func\n",
    "                    \n",
    "                    if typ == None:\n",
    "                        ## need function to get type of subphrase\n",
    "                        if node_type == 'subphrase':\n",
    "                            try:\n",
    "                                lower = t[pos][0].label()\n",
    "                                if lower == 'def':\n",
    "                                    lower = t[pos][1].label()\n",
    "                                typ = sub_dict[lower]\n",
    "                            except:\n",
    "                                typ = 'SP'\n",
    "                        else:\n",
    "                            typ = node_type\n",
    "                    new_label = typ + func\n",
    "                t[pos].set_label(new_label)\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "def build_tree(node):\n",
    "    \n",
    "    ''' Given a BHSA node, calls tree_string to build a tree from all lower distributional nodes then rearranges and cleans up. '''\n",
    "    # 1. Build tree using atoms\n",
    "    t = Tree.fromstring(tree_string(node))\n",
    "    \n",
    "    # 2. Move distributional nodes under function\n",
    "    move_func(t)\n",
    "    \n",
    "    # 3. Deal with mother/daughter relationships\n",
    "    # need to think about vocatives and resumption, but leave out for now\n",
    "    relations = ['adj','atr','dem','mod','rec','Adju','Appo','Attr','Cmpl','Objc','PrAd','PreC','RgRc','Spec','Subj']\n",
    "    move_daughter(t, relations)\n",
    "    \n",
    "    # 4. Deal with parallel and coordinated relations\n",
    "    move_para(t)   \n",
    "    \n",
    "    # 5. Move linking conjunction under new para phrase\n",
    "    relations = ['Link']\n",
    "    move_daughter(t, relations) \n",
    "            \n",
    "    # 5. Trim off empty nodes\n",
    "    trim_nodes(t)\n",
    "    \n",
    "    # 6. Collapse redundant nodes\n",
    "    collapse_nodes(t)\n",
    "    \n",
    "    # 7. Relabel nodes with phrase functions\n",
    "    relabel_tree(t)\n",
    "    \n",
    "    return(t)\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "def reference(node):\n",
    "    book = L.u(node, 'book')\n",
    "    chap = L.u(node, 'chapter')\n",
    "    verse = L.i(node, 'verse')\n",
    "    bk = Fs(\"book@en\").v(book[0])\n",
    "    ch = F.chapter.v(chap[0])\n",
    "    if len(verse) > 1:\n",
    "        vs_s = F.verse.v(verse[0])\n",
    "        vs_e = F.verse.v(verse[-1])\n",
    "        print('{} {}:{}-{}'.format(bk, ch, vs_s, vs_e))\n",
    "    else:\n",
    "        vs = F.verse.v(verse[0])\n",
    "        print('{} {}:{}'.format(bk, ch, vs))\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "def print_tree(t, node):\n",
    "    tree = t.copy()\n",
    "    slots = E.oslots.s(node)\n",
    "    words = []\n",
    "    for slot in slots:\n",
    "        words.append(F.phono.v(slot))\n",
    "                        \n",
    "    for pos in tree.treepositions():\n",
    "        try:\n",
    "            tree[pos].label()\n",
    "        except:\n",
    "            tree[pos] = slots.index(int(tree[pos]))\n",
    "            \n",
    "    tree.pretty_print(sentence=words, unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1563c5cb-c265-42a6-8d15-a8728a21934c",
   "metadata": {},
   "source": [
    "#### Step 1. Get sentences from Genesis and the Psalms\n",
    "\n",
    "I will use a search to return lists of the sentence nodes in the books of Genesis and Psalms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "25fce786-d273-4afa-97de-af8dccfdd5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.07s 4617 results\n",
      "  0.07s 5104 results\n"
     ]
    }
   ],
   "source": [
    "query1 = '''\n",
    "book book=Genesis\n",
    "    sentence\n",
    "'''\n",
    "\n",
    "query2 = '''\n",
    "book book=Psalmi\n",
    "    sentence\n",
    "'''\n",
    "\n",
    "genesis = A.search(query1)\n",
    "psalms = A.search(query2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711485f9-1b77-4414-8363-a736de563327",
   "metadata": {},
   "source": [
    "#### Step 2. Get grammatical features in each sentence\n",
    "\n",
    "Now for each sentence, we need to create a list of the grammatical features present. This will be saved as an observation in the list X, while the varaible Y stores the binary classification of the sentence(1 = Genesis, 0 = Psalms). The basic idea is to use the NLTK productions() to retrieve the grammar of the sentence. I will then use a custom function to add relevant grammatical features to the observation. I have already done a little work to transform some of the raw grammatical tags to more meaningful features, but this is one area that can use a little more work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e0fdadb4-29e6-4832-aca2-57527a81506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(node):\n",
    "    '''Function to retrieve list of grammatical features present in a sentence node '''\n",
    "    features=[]\n",
    "    t = build_tree(node)\n",
    "    for p in t.productions():\n",
    "        label = str(p.lhs())\n",
    "        if (label.startswith('NP') or\n",
    "             label.startswith('PP') or\n",
    "             label.startswith('VP') or\n",
    "             label.startswith('REL')):\n",
    "            features.append(label)\n",
    "        elif label.startswith('CLAUSE'):\n",
    "            if '0' in label:\n",
    "                features.append('0')\n",
    "            if 'Way' in label:\n",
    "                features.append('Wayyiqtol')\n",
    "            elif 'WQt' in label:\n",
    "                features.append('Weqatal')\n",
    "            elif 'W' in label:\n",
    "                features.append('Syndetic')\n",
    "            elif 'Z' in label:\n",
    "                features.append('Zero')\n",
    "            else:\n",
    "                features.append(label)\n",
    "        elif label == 'def':\n",
    "            word = int(p.rhs()[0])\n",
    "            if F.g_cons.v(word) == 'H':\n",
    "                features.append('DefArt')\n",
    "    return features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2344fab5-8f80-4df6-a11d-5d8b990c9bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "X = []\n",
    "nodes = []\n",
    "for sent in genesis:\n",
    "    node = sent[1]\n",
    "    nodes.append(node)\n",
    "    features = get_features(node)\n",
    "    Y.append(1)\n",
    "    X.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7dcc0f05-7f31-4b7d-9156-42a7d85eb2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in psalms:\n",
    "    node = sent[1]\n",
    "    nodes.append(node)\n",
    "    features = get_features(node)\n",
    "    Y.append(0)\n",
    "    X.append(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b3784-f531-4715-9a8a-71931eae30a5",
   "metadata": {},
   "source": [
    "#### Step 3. Convert feature lists to sparse array\n",
    "\n",
    "The classifier cannot understand text strings directly, so I will use the sklearn CountVectorizer to transform the data into an array with \"one hot\" encoding. In short, each feature will be indexed to a column of the resulting array X_count, with the value recording the count of that feature in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ebb932ce-8187-4c63-8c77-705e1a951907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "19ca9fe5-5f21-4feb-a1e0-caf8ec50af31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9721, 90)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a dummy function to bypass tokenizing since the features are already in list form\n",
    "def dummy(tokens):\n",
    "    return tokens\n",
    "\n",
    "count_vect = CountVectorizer(tokenizer = dummy,\n",
    "                            preprocessor = None,\n",
    "                            lowercase=False)\n",
    "\n",
    "X_counts = count_vect.fit_transform(X)\n",
    "X_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d47259b-f1ff-467c-aea7-7356aaf5cba4",
   "metadata": {},
   "source": [
    "#### Step 4. Variable Selection\n",
    "\n",
    "The resulting array has columns for 90 features. Since we are interested in interpretability, we do not want to keep this many features in the model. I will use forward selection to find the twenty most important features. (Note that this method is time consuming and won't scale well if we add more data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8a011a0f-4cc2-4585-a8c9-f440a2b2c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0)\n",
    "sfs_forward = SequentialFeatureSelector(clf, n_features_to_select=20, direction='forward').fit(X_counts, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77259a7e-d805-41a7-a122-baf803a90eab",
   "metadata": {},
   "source": [
    "The feature selector provides a get_support() method to return a mask with value True for the columns that were selected and False for those that were not. We can use this in combination with the get_feature_names() method from the count vectorizer above to retreive the names of the selected features. (Note that the names must be converted to an np.array to index them with the mask)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8f5a472b-54b5-442a-a532-d3c6c4a3f4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CLAUSE_Adju' 'CLAUSE_Coor' 'CLAUSE_Ellp' 'CLAUSE_Objc' 'CLAUSE_xQt0'\n",
      " 'CLAUSE_xQtX' 'DefArt' 'NP_Appo' 'NP_Exst' 'NP_Objc' 'NP_Time' 'NP_Voct'\n",
      " 'NP_adj' 'NP_par' 'PP_Objc' 'Syndetic' 'VP_rec' 'Wayyiqtol' 'Weqatal'\n",
      " 'Zero']\n"
     ]
    }
   ],
   "source": [
    "names = np.array(count_vect.get_feature_names())\n",
    "print(names[sfs_forward.get_support()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10318c8a-cf22-4e56-a598-a4c4bd67cd22",
   "metadata": {},
   "source": [
    "#### Step 5. Model fitting and Assessment\n",
    "\n",
    "Before fitting the model, we use the transform() method to drop the columns for features that were not selected from the X_counts array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8508f475-de1f-4068-9274-aae643e88b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = sfs_forward.transform(X_counts)\n",
    "fit = clf.fit(X_reduced, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8483a9e-1e7c-44c7-ad39-4ac1fc2fc604",
   "metadata": {},
   "source": [
    "In order to assess the model we can use precicision and recall scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6b8e3a4a-b37d-49e0-a0ba-ddffe7c033d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82      5104\n",
      "           1       0.84      0.68      0.76      4617\n",
      "\n",
      "    accuracy                           0.79      9721\n",
      "   macro avg       0.80      0.78      0.79      9721\n",
      "weighted avg       0.80      0.79      0.79      9721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_hat = fit.predict(X_reduced)\n",
    "print(metrics.classification_report(Y, Y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d52e923-0d94-411c-8d28-f1d39f01e215",
   "metadata": {},
   "source": [
    "The model was able to correctly classify roughly 80% of the sentences, which is frankly not all that great. This is due in part to the fact that a sentence is a relatively small unit, though, and we would likely do much better if we attempted to classify larger chunks of text. \n",
    "\n",
    "We can also look at our coefficients to get a sense of the importance of each variable. In short, the size of the coefficient is related to the odds that the observation is in the book of Genesis (positive values) or not (negative values). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "13733ff8-4728-4f52-88dd-632b241be223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wayyiqtol 2.5637751829412956\n",
      "Weqatal 1.7922871383232206\n",
      "NP_adj 1.6227008787816182\n",
      "PP_Objc 1.3044821616673163\n",
      "DefArt 1.2984609970510494\n",
      "NP_Exst 1.1636461847131085\n",
      "NP_Appo 0.9801416636840329\n",
      "CLAUSE_Objc 0.7233781493720222\n",
      "NP_par 0.6135745046900457\n",
      "CLAUSE_Adju 0.538748376274794\n",
      "Syndetic 0.42561222799574094\n",
      "CLAUSE_xQt0 0.38177504822438474\n",
      "CLAUSE_xQtX 0.34743457455790894\n",
      "NP_Objc -0.6107632416909925\n",
      "Zero -0.6413421310599826\n",
      "NP_Time -0.6563686114501577\n",
      "CLAUSE_Ellp -1.1038386686235526\n",
      "VP_rec -1.3446500858735173\n",
      "NP_Voct -1.4442116939035992\n",
      "CLAUSE_Coor -1.7491930642403388\n"
     ]
    }
   ],
   "source": [
    "values = fit.coef_.tolist()[0]\n",
    "for name, value in sorted(zip(names[sfs_forward.get_support()],values), key=lambda x: x[1], reverse=True):\n",
    "    print(name, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7845e2bc-94c4-4bd3-bfdf-4025f4c72aee",
   "metadata": {},
   "source": [
    "Most of these are not surprising. The presence of Wayyiqtol or Weqatal is the most significant indication that a sentence is likely from Genesis rather than the Psalms. The presence of the object marker (PP_Objc) or the consonantal article (DefArt) are also strong indicators of Genesis, while the absence of the object marker (NP_Objc) is an indicator of Psalms. Ellipsis and vocatives also make sense as indicators that a sentence is likely from the Psalms. The relative word *)asher* did not make the list despite it usually being clustered with the object marker and definite article as the \"prose particles\". Instead  but instead it seems that VP_rec \n",
    "\n",
    "The presence of a nominal phrase in an adjective position is a little surprising as an indication of Genesis, but this may relate to the \"terseness\" of poetry in the Psalms (see also NP_Appo). Note also that My sense is that it is simply not found frequently enough to be significant for this model where each observation is a sentence. If we looked at full chapters perhaps. \n",
    "\n",
    "Coordinated clauses are also prevalent in the tagging of the Psalms, but I am not sure to what extent this is influenced by expectations about genre. Namely, the coordinated clauses seem to be used to indicate poetic parallelism and I am not sure how consistent this is tagged. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
